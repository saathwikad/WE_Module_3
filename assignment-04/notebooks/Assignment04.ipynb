{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsZC3M7aEAP8WVtOAn4/aA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saathwikad/WE_Module_3/blob/main/assignment-04/notebooks/Assignment04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Generation - Assignment04"
      ],
      "metadata": {
        "id": "z1I1_K6h-_Lg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version - 1 - Chatgpt"
      ],
      "metadata": {
        "id": "PTlyFtKz_E-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus Generation - Cleaning(Tokenization)"
      ],
      "metadata": {
        "id": "Q49Q4a_CCiqK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tVwMMxx-6h5",
        "outputId": "bb090b38-8ffc-48ea-8b54-e1d7e27841f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Tokens:\n",
            "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'a', 'stitch', 'in', 'time', 'saves', 'nine', 'all', 'that', 'glitters', 'is', 'not', 'gold', 'actions', 'speak', 'louder', 'than', 'words', 'practice', 'makes', 'perfect']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_corpus(text):\n",
        "    # Remove punctuation marks\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Split text into tokens\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Sample text corpus\n",
        "text_corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A stitch in time saves nine.\n",
        "All that glitters is not gold.\n",
        "Actions speak louder than words.\n",
        "Practice makes perfect.\n",
        "\"\"\"\n",
        "\n",
        "# Clean the text corpus\n",
        "cleaned_tokens = clean_corpus(text_corpus)\n",
        "\n",
        "# Print the cleaned tokens\n",
        "print(\"Cleaned Tokens:\")\n",
        "print(cleaned_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cleaned Tokens:\")\n",
        "print(cleaned_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9uOvik2ARY7",
        "outputId": "fa3f787e-4049-4006-c939-f0439d553c65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Tokens:\n",
            "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'a', 'stitch', 'in', 'time', 'saves', 'nine', 'all', 'that', 'glitters', 'is', 'not', 'gold', 'actions', 'speak', 'louder', 'than', 'words', 'practice', 'makes', 'perfect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function with internal corpus. Tested on sample testcases given by GPT."
      ],
      "metadata": {
        "id": "tBA0sJtgC1XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_internal_corpus(start_words: list[str], chain_length: int, num_generated: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate a sentence similar to the sample text corpus provided in the code.\n",
        "\n",
        "    Parameters:\n",
        "        start_words (list[str]): A list of starting words, exactly as long as the chain_length.\n",
        "        chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "        num_generated (int): The number of words in the generated sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated sentence.\n",
        "    \"\"\"\n",
        "    # Sample text corpus provided in the code\n",
        "    sample_corpus = \"\"\"\n",
        "    The quick brown fox jumps over the lazy dog.\n",
        "    A stitch in time saves nine.\n",
        "    All that glitters is not gold.\n",
        "    Actions speak louder than words.\n",
        "    Practice makes perfect.\n",
        "    \"\"\"\n",
        "\n",
        "    # Clean the text corpus\n",
        "    tokens = clean_corpus(sample_corpus)\n",
        "\n",
        "    try:\n",
        "        # Build the Markov chain\n",
        "        markov_chain = build_markov_chain(tokens, chain_length)\n",
        "\n",
        "        # Generate a sentence using the Markov chain and starting words\n",
        "        current_words = start_words.copy()\n",
        "        generated_sentence = list(current_words)\n",
        "\n",
        "        for _ in range(num_generated):\n",
        "            current_state = tuple(current_words)\n",
        "            if current_state in markov_chain:\n",
        "                next_word = max(markov_chain[current_state], key=markov_chain[current_state].get)\n",
        "                generated_sentence.append(next_word)\n",
        "                current_words = generated_sentence[-chain_length:]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return ' '.join(generated_sentence)\n",
        "\n",
        "    except ValueError as e:\n",
        "        return f\"Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# Test the generate_with_internal_corpus function\n",
        "start_words = [\"the\", \"quick\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpGrrWqlAW9g",
        "outputId": "eba046b4-0931-4fba-9729-6864ee00e544"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: the quick brown fox jumps over the lazy dog a stitch in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te following four testcases are given by GPT."
      ],
      "metadata": {
        "id": "5W2dN6EsEV5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 1\n",
        "start_words = [\"the\", \"quick\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "t3NM2m4zDFyF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEtRKh02DMob",
        "outputId": "b99a9d55-341a-4755-d389-248c4a056edd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: the quick brown fox jumps over the lazy dog a stitch in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = [\"practice\", \"makes\"]\n",
        "chain_length = 3\n",
        "num_generated = 7\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "GqCZTnWVDOpk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Sentence:\", generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG4FZXfvDOz9",
        "outputId": "457c180a-a0e7-4d83-e283-67f36409b36d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: practice makes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = [\"the\"]\n",
        "chain_length = 0  # Invalid chain length (less than 1)\n",
        "num_generated = 5\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "Nb5bB6OrDO9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0lWfsGJDPHI",
        "outputId": "a35a1fe4-a699-4377-df7b-050c3ddab522"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = []\n",
        "chain_length = 2\n",
        "num_generated = 7\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "lb9prLDHDc8q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18B45S7oDdAh",
        "outputId": "f4250f72-5089-4a9b-f35e-33f9f90055ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My testcases for GPT."
      ],
      "metadata": {
        "id": "UPnssvNZEbUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = [\"I\", \"am\", \"a\"]\n",
        "chain_length = 3\n",
        "num_generated = 10\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "VVxza6HHEdgT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqm3GbXHFAqZ",
        "outputId": "b788274f-9620-41ce-f8f8-850f76703887"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: I am a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_internal_corpus(start_words: list[str], chain_length: int, num_generated: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate a sentence similar to the sample text corpus provided in the code.\n",
        "\n",
        "    Parameters:\n",
        "        start_words (list[str]): A list of starting words.\n",
        "        chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "        num_generated (int): The number of words in the generated sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated sentence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Sample text corpus provided in the code\n",
        "        sample_corpus = \"\"\"\n",
        "        The quick brown fox jumps over the lazy dog.\n",
        "        A stitch in time saves nine.\n",
        "        All that glitters is not gold.\n",
        "        Actions speak louder than words.\n",
        "        Practice makes perfect.\n",
        "        \"\"\"\n",
        "\n",
        "        # Clean the text corpus\n",
        "        tokens = clean_corpus(sample_corpus)\n",
        "\n",
        "        # Validate chain length\n",
        "        if chain_length <= 0:\n",
        "            raise ValueError(\"Chain length must be a positive integer.\")\n",
        "\n",
        "        # Randomly select starting words if not provided\n",
        "        if not start_words:\n",
        "            start_words = random.sample(tokens, chain_length)\n",
        "\n",
        "        # Build the Markov chain\n",
        "        markov_chain = build_markov_chain(tokens, chain_length)\n",
        "\n",
        "        # Generate a sentence using the Markov chain and starting words\n",
        "        current_words = start_words.copy()\n",
        "        generated_sentence = list(current_words)\n",
        "\n",
        "        for _ in range(num_generated):\n",
        "            current_state = tuple(current_words)\n",
        "            if current_state in markov_chain:\n",
        "                next_word = max(markov_chain[current_state], key=markov_chain[current_state].get)\n",
        "                generated_sentence.append(next_word)\n",
        "                current_words = generated_sentence[-chain_length:]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return ' '.join(generated_sentence)\n",
        "\n",
        "    except ValueError as e:\n",
        "        return f\"Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "\n",
        "# Sample Test Cases\n",
        "print(\"Sample Test Cases:\")\n",
        "print(\"------------------\")\n",
        "\n",
        "# Test Case 1: Generate sentence with specified start words\n",
        "start_words = [\"the\", \"quick\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence (Specified Start Words):\", generated_sentence)\n",
        "\n",
        "# Test Case 2: Generate sentence with random start words\n",
        "chain_length = 3\n",
        "num_generated = 7\n",
        "generated_sentence = generate_with_internal_corpus([], chain_length, num_generated)\n",
        "print(\"Generated Sentence (Random Start Words):\", generated_sentence)\n",
        "\n",
        "# Test Case 3: Invalid chain length\n",
        "chain_length = 0  # Invalid chain length (less than 1)\n",
        "num_generated = 5\n",
        "generated_sentence = generate_with_internal_corpus([], chain_length, num_generated)\n",
        "print(\"Generated Sentence (Invalid Chain Length):\", generated_sentence)\n",
        "\n",
        "# Test Case 4: Empty starting words\n",
        "start_words = []\n",
        "chain_length = 2\n",
        "num_generated = 7\n",
        "generated_sentence = generate_with_internal_corpus(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence (Empty Starting Words):\", generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axg3QkWmM5ut",
        "outputId": "af501f31-caae-4e0e-f9f2-1e4a01b89997"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test Cases:\n",
            "------------------\n",
            "Generated Sentence (Specified Start Words): the quick brown fox jumps over the lazy dog a stitch in\n",
            "Generated Sentence (Random Start Words): An unexpected error occurred: name 'random' is not defined\n",
            "Generated Sentence (Invalid Chain Length): Error: Chain length must be a positive integer.\n",
            "Generated Sentence (Empty Starting Words): An unexpected error occurred: name 'random' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_corpus(text):\n",
        "    \"\"\"\n",
        "    Clean the text corpus by removing punctuation marks and converting to lowercase.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text corpus to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of cleaned tokens (words).\n",
        "    \"\"\"\n",
        "    cleaned_text = text.lower()\n",
        "    cleaned_text = ''.join([char for char in cleaned_text if char.isalnum() or char.isspace()])\n",
        "    tokens = cleaned_text.split()\n",
        "    return tokens\n",
        "\n",
        "def build_markov_chain(tokens, chain_length):\n",
        "    \"\"\"\n",
        "    Build a Markov chain dictionary based on the given list of tokens and chain length.\n",
        "\n",
        "    Parameters:\n",
        "        tokens (list[str]): The list of cleaned tokens (words) from the text corpus.\n",
        "        chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "\n",
        "    Returns:\n",
        "        dict: The Markov chain dictionary.\n",
        "    \"\"\"\n",
        "    markov_chain = {}\n",
        "\n",
        "    for i in range(len(tokens) - chain_length):\n",
        "        # Construct the current state (sequence of words)\n",
        "        current_state = tuple(tokens[i:i + chain_length])\n",
        "        # Get the next word after the current state\n",
        "        next_word = tokens[i + chain_length]\n",
        "\n",
        "        # Update the Markov chain dictionary\n",
        "        if current_state in markov_chain:\n",
        "            if next_word in markov_chain[current_state]:\n",
        "                markov_chain[current_state][next_word] += 1\n",
        "            else:\n",
        "                markov_chain[current_state][next_word] = 1\n",
        "        else:\n",
        "            markov_chain[current_state] = {next_word: 1}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LoGZnCYvNVMV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Oriented Approach by GPT."
      ],
      "metadata": {
        "id": "ICU2ef3BPGWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator:\n",
        "    def __init__(self, text_corpus):\n",
        "        self.tokens = self.clean_corpus(text_corpus)\n",
        "        self.markov_chain = {}\n",
        "\n",
        "    def clean_corpus(self, text):\n",
        "        \"\"\"\n",
        "        Clean the text corpus by removing punctuation marks and converting to lowercase.\n",
        "\n",
        "        Parameters:\n",
        "            text (str): The text corpus to be cleaned.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: A list of cleaned tokens (words).\n",
        "        \"\"\"\n",
        "        cleaned_text = text.lower()\n",
        "        cleaned_text = ''.join([char for char in cleaned_text if char.isalnum() or char.isspace()])\n",
        "        tokens = cleaned_text.split()\n",
        "        return tokens\n",
        "\n",
        "    def build_markov_chain(self, chain_length):\n",
        "        \"\"\"\n",
        "        Build a Markov chain dictionary based on the given list of tokens and chain length.\n",
        "\n",
        "        Parameters:\n",
        "            chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "\n",
        "        Returns:\n",
        "            dict: The Markov chain dictionary.\n",
        "        \"\"\"\n",
        "        self.markov_chain = {}\n",
        "\n",
        "        for i in range(len(self.tokens) - chain_length):\n",
        "            # Construct the current state (sequence of words)\n",
        "            current_state = tuple(self.tokens[i:i + chain_length])\n",
        "            # Get the next word after the current state\n",
        "            next_word = self.tokens[i + chain_length]\n",
        "\n",
        "            # Update the Markov chain dictionary\n",
        "            if current_state in self.markov_chain:\n",
        "                if next_word in self.markov_chain[current_state]:\n",
        "                    self.markov_chain[current_state][next_word] += 1\n",
        "                else:\n",
        "                    self.markov_chain[current_state][next_word] = 1\n",
        "            else:\n",
        "                self.markov_chain[current_state] = {next_word: 1}\n",
        "\n",
        "    def generate_sentence(self, start_words, chain_length, num_generated):\n",
        "        \"\"\"\n",
        "        Generate a sentence using the Markov chain model.\n",
        "\n",
        "        Parameters:\n",
        "            start_words (list[str]): A list of starting words.\n",
        "            chain_length (int): The length of the Markov chain.\n",
        "            num_generated (int): The number of words in the generated sentence.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated sentence.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Build the Markov chain\n",
        "            self.build_markov_chain(chain_length)\n",
        "\n",
        "            # Generate a sentence using the Markov chain and starting words\n",
        "            current_words = start_words.copy()\n",
        "            generated_sentence = list(current_words)\n",
        "\n",
        "            for _ in range(num_generated):\n",
        "                current_state = tuple(current_words)\n",
        "                if current_state in self.markov_chain:\n",
        "                    next_word = max(self.markov_chain[current_state], key=self.markov_chain[current_state].get)\n",
        "                    generated_sentence.append(next_word)\n",
        "                    current_words = generated_sentence[-chain_length:]\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            return ' '.join(generated_sentence)\n",
        "\n",
        "        except ValueError as e:\n",
        "            return f\"Error: {e}\"\n",
        "        except Exception as e:\n",
        "            return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# Test the TextGenerator class\n",
        "text_corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A stitch in time saves nine.\n",
        "All that glitters is not gold.\n",
        "Actions speak louder than words.\n",
        "Practice makes perfect.\n",
        "\"\"\"\n",
        "\n",
        "text_generator = TextGenerator(text_corpus)\n",
        "#Testcase 1 by GPT\n",
        "start_words = [\"the\", \"quick\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = text_generator.generate_sentence(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)\n",
        "#Testcase 2 by GPT\n",
        "start_words = [\"practice\", \"makes\"]\n",
        "chain_length = 2\n",
        "num_generated = 7\n",
        "generated_sentence = text_generator.generate_sentence(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGjQ1mbZNcCN",
        "outputId": "dab7673e-5e93-4f64-8afb-a514d8ff449a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: the quick brown fox jumps over the lazy dog a stitch in\n",
            "Generated Sentence: practice makes perfect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Working Version."
      ],
      "metadata": {
        "id": "-UlXY1q_O1sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator:\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "\n",
        "    def clean_corpus(self):\n",
        "        \"\"\"\n",
        "        Clean the text corpus by removing punctuation marks and converting to lowercase.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: A list of cleaned tokens (words).\n",
        "        \"\"\"\n",
        "        cleaned_text = self.corpus.lower()\n",
        "        cleaned_text = ''.join([char for char in cleaned_text if char.isalnum() or char.isspace()])\n",
        "        tokens = cleaned_text.split()\n",
        "        return tokens\n",
        "\n",
        "    def build_markov_chain(self, tokens, chain_length):\n",
        "        \"\"\"\n",
        "        Build a Markov chain dictionary based on the given list of tokens and chain length.\n",
        "\n",
        "        Parameters:\n",
        "            tokens (list[str]): The list of cleaned tokens (words) from the text corpus.\n",
        "            chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "\n",
        "        Returns:\n",
        "            dict: The Markov chain dictionary.\n",
        "        \"\"\"\n",
        "        markov_chain = {}\n",
        "\n",
        "        for i in range(len(tokens) - chain_length):\n",
        "            # Construct the current state (sequence of words)\n",
        "            current_state = tuple(tokens[i:i + chain_length])\n",
        "            # Get the next word after the current state\n",
        "            next_word = tokens[i + chain_length]\n",
        "\n",
        "            # Update the Markov chain dictionary\n",
        "            if current_state in markov_chain:\n",
        "                if next_word in markov_chain[current_state]:\n",
        "                    markov_chain[current_state][next_word] += 1\n",
        "                else:\n",
        "                    markov_chain[current_state][next_word] = 1\n",
        "            else:\n",
        "                markov_chain[current_state] = {next_word: 1}\n",
        "\n",
        "        return markov_chain\n",
        "\n",
        "    def generate_sentence(self, start_words, chain_length, num_generated):\n",
        "        \"\"\"\n",
        "        Generate a sentence using the Markov chain based on the provided starting words, chain length, and number of words to generate.\n",
        "\n",
        "        Parameters:\n",
        "            start_words (list[str]): A list of starting words.\n",
        "            chain_length (int): The length of the Markov chain.\n",
        "            num_generated (int): The number of words in the generated sentence.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated sentence.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Clean the text corpus\n",
        "            tokens = self.clean_corpus()\n",
        "\n",
        "            # Build the Markov chain\n",
        "            markov_chain = self.build_markov_chain(tokens, chain_length)\n",
        "\n",
        "            # Generate a sentence using the Markov chain and starting words\n",
        "            current_words = start_words.copy()\n",
        "            generated_sentence = list(current_words)\n",
        "\n",
        "            for _ in range(num_generated):\n",
        "                current_state = tuple(current_words)\n",
        "                if current_state in markov_chain:\n",
        "                    next_word = max(markov_chain[current_state], key=markov_chain[current_state].get)\n",
        "                    generated_sentence.append(next_word)\n",
        "                    current_words = generated_sentence[-chain_length:]\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            return ' '.join(generated_sentence)\n",
        "\n",
        "        except ValueError as e:\n",
        "            return f\"Error: {e}\"\n",
        "        except Exception as e:\n",
        "            return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# Sample Test Cases\n",
        "corpus = \"\"\"\n",
        "    The quick brown fox jumps over the lazy dog.\n",
        "    A stitch in time saves nine.\n",
        "    All that glitters is not gold.\n",
        "    Actions speak louder than words.\n",
        "    Practice makes perfect.\n",
        "    \"\"\"\n",
        "\n",
        "generator = TextGenerator(corpus)\n",
        "\n",
        "# Test Case 1\n",
        "start_words = [\"the\", \"quick\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generator.generate_sentence(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)\n",
        "\n",
        "# Test Case 2\n",
        "start_words = [\"practice\", \"makes\"]\n",
        "chain_length = 3\n",
        "num_generated = 7\n",
        "generated_sentence = generator.generate_sentence(start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWScwRwoNcLN",
        "outputId": "f4533f09-b6f0-4137-8dbb-e8eb5da07feb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: the quick brown fox jumps over the lazy dog a stitch in\n",
            "Generated Sentence: practice makes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Own Testcases"
      ],
      "metadata": {
        "id": "YPyAUKPMPWLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = [\"all\", \"that\"]\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generator.generate_sentence(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "AfzFb3kHNZWl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33O89xlwNcXT",
        "outputId": "4d867f9e-f4b0-4c70-d105-6147615fe206"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all that glitters is not gold actions speak louder than words practice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_words = [\"practice\", \"makes\"]\n",
        "chain_length = 2\n",
        "num_generated = 7\n",
        "generated_sentence = generator.generate_sentence(start_words, chain_length, num_generated)"
      ],
      "metadata": {
        "id": "zzti4gVcP3Qc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_sentence)\n",
        "#not working"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO6h6oJ6P4qu",
        "outputId": "9ac51af4-2541-47dc-9469-e151e6bdaf63"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "practice makes perfect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function handling exceptions, errors. Requires sample external corpus. Yet to be tested."
      ],
      "metadata": {
        "id": "liU5GefCCq4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_external_corpus(filename: str, start_words: list[str], chain_length: int, num_generated: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate a sentence similar to the text contained in the specified file.\n",
        "\n",
        "    Parameters:\n",
        "        filename (str): The path to the file containing the text corpus.\n",
        "        start_words (list[str]): A list of starting words, exactly as long as the chain_length.\n",
        "        chain_length (int): The length of the Markov chain, determining the number of previous words considered for prediction.\n",
        "        num_generated (int): The number of words in the generated sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated sentence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read text from the file\n",
        "        with open(filename, 'r') as file:\n",
        "            text_corpus = file.read()\n",
        "\n",
        "        # Clean the text corpus\n",
        "        tokens = clean_corpus(text_corpus)\n",
        "\n",
        "        # Validate chain length\n",
        "        if chain_length <= 0:\n",
        "            raise ValueError(\"Chain length must be a positive integer.\")\n",
        "\n",
        "        # Validate starting words\n",
        "        if len(start_words) != chain_length:\n",
        "            raise ValueError(\"The number of starting words must be equal to the chain length.\")\n",
        "\n",
        "        # Build the Markov chain\n",
        "        markov_chain = build_markov_chain(tokens, chain_length)\n",
        "\n",
        "        # Generate a sentence using the Markov chain and starting words\n",
        "        current_words = start_words.copy()\n",
        "        generated_sentence = list(current_words)\n",
        "\n",
        "        for _ in range(num_generated):\n",
        "            current_state = tuple(current_words)\n",
        "            if current_state in markov_chain:\n",
        "                next_word = max(markov_chain[current_state], key=markov_chain[current_state].get)\n",
        "                generated_sentence.append(next_word)\n",
        "                current_words = generated_sentence[-chain_length:]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return ' '.join(generated_sentence)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: File '{filename}' not found.\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# Test the generate_with_external_corpus function\n",
        "filename = \"sample_corpus.txt\"  # Provide the path to the text corpus file\n",
        "start_words = [\"the\", \"quick\"]  # Provide the starting words\n",
        "chain_length = 2\n",
        "num_generated = 10\n",
        "generated_sentence = generate_with_external_corpus(filename, start_words, chain_length, num_generated)\n",
        "print(\"Generated Sentence:\", generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipSyywPHAS40",
        "outputId": "e715ecdc-a2ba-45ba-ed75-c43759a113cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: Error: File 'sample_corpus.txt' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5QLfrPtpCRsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}